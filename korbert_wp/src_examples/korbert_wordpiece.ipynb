{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 30754,
     "status": "ok",
     "timestamp": 1606955799514,
     "user": {
      "displayName": "김승혁",
      "photoUrl": "",
      "userId": "03597292082641904287"
     },
     "user_tz": -540
    },
    "id": "fZENuxErkRYY",
    "outputId": "75533149-f78f-4879-815a-2ab22d321630"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 9039,
     "status": "ok",
     "timestamp": 1606955817113,
     "user": {
      "displayName": "김승혁",
      "photoUrl": "",
      "userId": "03597292082641904287"
     },
     "user_tz": -540
    },
    "id": "r9ddyBN4kRWD",
    "outputId": "139deb7a-fc22-46b9-fc83-c3922fb216b7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pytorch_pretrained_bert\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d7/e0/c08d5553b89973d9a240605b9c12404bcf8227590de62bae27acbcfe076b/pytorch_pretrained_bert-0.6.2-py3-none-any.whl (123kB)\n",
      "\u001b[K     |████████████████████████████████| 133kB 3.9MB/s \n",
      "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (2.23.0)\n",
      "Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (2019.12.20)\n",
      "Requirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (1.7.0+cu101)\n",
      "Collecting boto3\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b7/df/6c160e21a5caa800de16f2aa859b92671623118b4d124639aeab06876c06/boto3-1.16.28-py2.py3-none-any.whl (129kB)\n",
      "\u001b[K     |████████████████████████████████| 133kB 17.8MB/s \n",
      "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (4.41.1)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (1.18.5)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch_pretrained_bert) (2020.11.8)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch_pretrained_bert) (2.10)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch_pretrained_bert) (1.24.3)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch_pretrained_bert) (3.0.4)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch>=0.4.1->pytorch_pretrained_bert) (3.7.4.3)\n",
      "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch>=0.4.1->pytorch_pretrained_bert) (0.16.0)\n",
      "Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from torch>=0.4.1->pytorch_pretrained_bert) (0.8)\n",
      "Collecting s3transfer<0.4.0,>=0.3.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/69/79/e6afb3d8b0b4e96cefbdc690f741d7dd24547ff1f94240c997a26fa908d3/s3transfer-0.3.3-py2.py3-none-any.whl (69kB)\n",
      "\u001b[K     |████████████████████████████████| 71kB 6.2MB/s \n",
      "\u001b[?25hCollecting botocore<1.20.0,>=1.19.28\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ac/e0/966b82eb9eab5fe36e80bcbbfda0d3f49cdd9ec896ebe9edb9824f896cd7/botocore-1.19.28-py2.py3-none-any.whl (7.0MB)\n",
      "\u001b[K     |████████████████████████████████| 7.0MB 15.2MB/s \n",
      "\u001b[?25hCollecting jmespath<1.0.0,>=0.7.1\n",
      "  Downloading https://files.pythonhosted.org/packages/07/cb/5f001272b6faeb23c1c9e0acc04d48eaaf5c862c17709d20e3469c6e0139/jmespath-0.10.0-py2.py3-none-any.whl\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.20.0,>=1.19.28->boto3->pytorch_pretrained_bert) (2.8.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.20.0,>=1.19.28->boto3->pytorch_pretrained_bert) (1.15.0)\n",
      "\u001b[31mERROR: botocore 1.19.28 has requirement urllib3<1.27,>=1.25.4; python_version != \"3.4\", but you'll have urllib3 1.24.3 which is incompatible.\u001b[0m\n",
      "Installing collected packages: jmespath, botocore, s3transfer, boto3, pytorch-pretrained-bert\n",
      "Successfully installed boto3-1.16.28 botocore-1.19.28 jmespath-0.10.0 pytorch-pretrained-bert-0.6.2 s3transfer-0.3.3\n"
     ]
    }
   ],
   "source": [
    "# 매번 설치필요\n",
    "!pip install pytorch_pretrained_bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D5Nsvo5mkRai"
   },
   "outputs": [],
   "source": [
    "# 작업디렉토리 설정\n",
    "# 파일을 저장한 공간에 맞게 경로를 수정\n",
    "# run_classifier_morp.py 가 있는 위치\n",
    "import os \n",
    "os.chdir('/content/drive/MyDrive/Colab Notebooks/kobert_wp/src_examples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SrkHaUD33LLL"
   },
   "outputs": [],
   "source": [
    "# pytorch_wordpiece 모델\n",
    "# etri_bert를 사용한 fine tuning\n",
    "# 사전학습된 모델을 통해 분류모델을 학습\n",
    "# vocab.korean.rawtext.list를 통해서 토큰화의 기준이 되는 단어 확인 가능\n",
    "# data_dir에는 train, dev(test), label 파일이 있어야함\n",
    "# do_train, do_eval은 입력값 없이 존재만하면 True 값을 리턴(사용하지 않을시 삭제필요)\n",
    "# bert_model_path에 지정된 폴더에는 model.bin, config 파일이 있어야함\n",
    "# output_dir의 경우 폴더에 파일이 존재할 시 에러 발생, 파일을 비움 or 새로운 경로지정\n",
    "!python run_classifier_morp.py \\\n",
    "  --task_name cola \\\n",
    "  --do_train \\\n",
    "  --do_eval \\\n",
    "  --data_dir ./fire \\\n",
    "  --vocab_file vocab.korean.rawtext.list \\\n",
    "  --bert_model_path ./dew \\\n",
    "  --max_seq_length 128 \\\n",
    "  --train_batch_size 4 \\\n",
    "  --learning_rate 2e-5 \\\n",
    "  --num_train_epochs 2.0 \\\n",
    "  --output_dir ./output3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T0e-WJxo3XcF"
   },
   "outputs": [],
   "source": [
    "# f1_score 계산\n",
    "# list 형식으로 데이터를 입력\n",
    "# 정답과, 예측 라벨 input\n",
    "def f1_score(test, predict):\n",
    "\n",
    "    if len(test) != len(predict):\n",
    "        return print('예측과 정답의 길이가 다름')\n",
    "\n",
    "    f1_df = [[0 for i in range(len(set(test)))] for i in range(len(set(test)))]\n",
    "\n",
    "        \n",
    "    for i in range(len(test)):\n",
    "        colums = predict[i]\n",
    "        idx =  test[i]\n",
    "        f1_df[idx][colums] += 1\n",
    "\n",
    "    recall = 0\n",
    "    for i in range(len(set(test))):\n",
    "        if sum(f1_df[i]) != 0 :\n",
    "            recall +=f1_df[i][i]/sum(f1_df[i])\n",
    "        else:\n",
    "            recall += 0\n",
    "\n",
    "    precision = 0\n",
    "    for i in range(len(set(test))):\n",
    "        \n",
    "        total = 0\n",
    "        for j in range(len(set(test))):\n",
    "            total += f1_df[j][i]\n",
    "\n",
    "        if total != 0 :\n",
    "            precision +=f1_df[i][i]/total\n",
    "            \n",
    "        else:\n",
    "            precision += 0\n",
    " \n",
    "    recall = recall/6\n",
    "    precision = precision/6\n",
    "    f1_score = 2*(precision*recall)/(precision+recall)\n",
    "    return f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 881,
     "status": "ok",
     "timestamp": 1606889803282,
     "user": {
      "displayName": "김승혁",
      "photoUrl": "",
      "userId": "03597292082641904287"
     },
     "user_tz": -540
    },
    "id": "fJ-L4QRYfoJ8",
    "outputId": "87608297-1a75-428a-fa1b-ba36a92aa93e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7252500946784544"
      ]
     },
     "execution_count": 15,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# dev에서 정답 라벨을 추출\n",
    "test  = pd.read_csv('./fire/dev.tsv', sep='\\t',encoding = 'utf-8',header =None)\n",
    "test = [ test[1].values[i] for i in range(len(test))]\n",
    "\n",
    "# 예측결과가 저장된 output 폴더에서 예측 라벨을 호출\n",
    "f = open('./output7/eval_results_labels.txt', 'r',encoding = 'utf-8')\n",
    "predict_list = [int(i) for i in f]\n",
    "f.close()\n",
    "\n",
    "f1_score(test, predict_list) # f1계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6301,
     "status": "ok",
     "timestamp": 1606959397922,
     "user": {
      "displayName": "김승혁",
      "photoUrl": "",
      "userId": "03597292082641904287"
     },
     "user_tz": -540
    },
    "id": "elOGCEHwhI0j",
    "outputId": "341d54bf-5402-4b1a-a442-28030ae579c5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 1/1 [00:00<00:00, 486.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "# 단일 문장을 예측하는 코드\n",
    "\n",
    "import argparse\n",
    "import csv\n",
    "import logging\n",
    "import os\n",
    "import random\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import (DataLoader, RandomSampler, SequentialSampler,\n",
    "                              TensorDataset)\n",
    "from torch.utils.data.distributed import DistributedSampler\n",
    "from tqdm import tqdm, trange\n",
    "\n",
    "from pytorch_pretrained_bert.file_utils import PYTORCH_PRETRAINED_BERT_CACHE\n",
    "from pytorch_pretrained_bert.modeling import BertForSequenceClassification, BertConfig, WEIGHTS_NAME, CONFIG_NAME \n",
    "\n",
    "from src_tokenizer.tokenization import BertTokenizer # 수정\n",
    "from pytorch_pretrained_bert.optimization import BertAdam, WarmupLinearSchedule # 수정\n",
    "\n",
    "import urllib3\n",
    "import json\n",
    "\n",
    "# 위의 bert 입력값과 동일\n",
    "data_dir = './fire'\n",
    "task_name = 'cola'\n",
    "output_dir = './output1'  \n",
    "vocab_file = 'vocab.korean.rawtext.list'\n",
    "cache_dir = \"\"\n",
    "max_seq_length = 128\n",
    "eval_batch_size = 8\n",
    "local_rank = -1\n",
    "seed = 42\n",
    "gradient_accumulation_steps = 1\n",
    "\n",
    "# 데이터 라벨에 따라 list 값을 수정해야함\n",
    "label_list = ['0', '1', '2', '3', '4', '5']\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(vocab_file, do_lower_case=False)\n",
    "\n",
    "cache_dir = cache_dir if cache_dir else os.path.join(str(PYTORCH_PRETRAINED_BERT_CACHE), 'distributed_{}'.format(local_rank))\n",
    "model = BertForSequenceClassification.from_pretrained(output_dir,\n",
    "              cache_dir=cache_dir,\n",
    "              num_labels = 6) # num_labels_task 라벨의 길이에 맞춰야함 or len(label_list)\n",
    "model.to(device)\n",
    "param_optimizer = list(model.named_parameters())\n",
    "no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n",
    "optimizer_grouped_parameters = [\n",
    "        {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n",
    "        {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], 'wei\n",
    "         \n",
    "\n",
    "global_step = 0\n",
    "nb_tr_steps = 0\n",
    "tr_loss = 0\n",
    "\n",
    "############## tokens_a에 예측하고 싶은 문장을 추가\n",
    "\n",
    "tokens_a = ''\n",
    "tokens_a = '목격자 김계동(남/42년생)에 의하면 화재 장소 주변에 볼일이 있어서 이동중 공동묘지 부근에서 연기가 발생하고 있어 확인해보니 공동묘지에서 화재가 발생하고 있었다고 진술함.  - 선착대 안면센터, 안면읍의용소방대 현장도착하여, 공동묘지 임야 화재진압 및 연소확대 방지조치 실시함.  - 현장조사한 바, 인적이 드문 공동묘지에서 발생한 화재로 현장에서 실화자를 확인할 수는 없었으나, 현장에서 특별한 발화원이 식별되지 않는 점, 공동묘지에서 발생한 화재인 점으로 보아 미상의 성묘객이 성묘후 발생한 담뱃불이 지피물에 착화되어 발생한 화재로 추정됨. '\n",
    "tokens_a = tokenizer.tokenize(tokens_a)     # 토큰화\n",
    "\n",
    "if len(tokens_a) > max_seq_length -2:\n",
    "    tokens_a = tokens_a[:(max_seq_length-2)] # max_seq_length에 맞게 길이를 조절\n",
    "tokens = [\"[CLS]\"] + tokens_a + [\"[SEP]\"] \n",
    "segment_ids = [0] * len(tokens) # 문장이 2개 이어진게 아니기 때문에 문장구분을 안해도됨\n",
    "input_ids = tokenizer.convert_tokens_to_ids(tokens) # 인덱싱\n",
    "input_mask = [1] * len(input_ids)\n",
    "padding = [0] * (max_seq_length - len(input_ids))\n",
    "input_ids += padding\n",
    "input_mask += padding\n",
    "segment_ids += padding\n",
    "label_id = 3\n",
    "# input data의 길이가 지정된 길이와 동일하게 고정\n",
    "assert len(input_ids) == max_seq_length\n",
    "assert len(input_mask) == max_seq_length\n",
    "assert len(segment_ids) == max_seq_length\n",
    "\n",
    "\n",
    "# 전처리\n",
    "# input하고 싶은 데이터를 전처리해주는 함수를 봐야함 convert_examples_to_features 분해\n",
    "# tensor 입력\n",
    "all_input_ids = torch.tensor([input_ids ], dtype=torch.long)\n",
    "all_input_mask = torch.tensor([input_mask ], dtype=torch.long)\n",
    "all_segment_ids = torch.tensor([segment_ids], dtype=torch.long)\n",
    "all_label_ids = torch.tensor([label_id ], dtype=torch.long)\n",
    "\n",
    "# Dataset 구성 문장인덱스, 마스킹, 문장분류, 라벨\n",
    "eval_data = TensorDataset(all_input_ids, all_input_mask, all_segment_ids, all_label_ids)\n",
    "eval_sampler = SequentialSampler(eval_data)\n",
    "eval_dataloader = DataLoader(eval_data, sampler=eval_sampler, batch_size=eval_batch_size)\n",
    "\n",
    "# 평가모드\n",
    "model.eval()\n",
    "\n",
    "for input_ids, input_mask, segment_ids , label_ids in tqdm(eval_dataloader, desc=\"Evaluating\"):\n",
    "        input_ids = input_ids.to(device)\n",
    "        input_mask = input_mask.to(device)\n",
    "        segment_ids = segment_ids.to(device) # 예측만하면 되서 정답은 생략\n",
    "        \n",
    "with torch.no_grad():\n",
    "        \n",
    "        logits = model(input_ids, segment_ids, input_mask)\n",
    "\n",
    "logits = logits.detach().cpu().numpy()\n",
    "current_out = np.argmax(logits, axis=1)\n",
    "\n",
    "# 결과값 pre\n",
    "# dictionary를 통해서 문장으로 바꾸면됨\n",
    "for key in current_out:\n",
    "    pre = int(key)\n",
    "    print(pre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fp-9yT-Iarj0"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "korbert_wordpiece.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
