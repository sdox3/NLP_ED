{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"BI-LSTM + CRF.ipynb","provenance":[],"private_outputs":true,"collapsed_sections":[],"mount_file_id":"1ED8Vbxw9aLxn8mFWTQDm0gieNr3NrjcF","authorship_tag":"ABX9TyMlRYXVuSzC8nkPBgbJpA3x"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"-64Owlkd4_te"},"source":["# 2.2.4에서 crf가 원활하게 구동됨, 코랩으로 구동 시 install뒤 런타임을 재실행해야함\n","\n","#!pip install git+https://www.github.com/keras-team/keras-contrib.git\n","#!pip install tensorflow==1.14.0\n","#!pip install keras==2.2.4\n","#!pip install tensorflow-gpu==1.14.0\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"RhCtLcWMq0vH"},"source":["import pandas as pd\n","import numpy as np\n","%matplotlib inline\n","import matplotlib.pyplot as plt\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","from sklearn.model_selection import train_test_split\n","from tensorflow.keras.utils import to_categorical"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4r0xkGlv3_Ml"},"source":["# import zipfile\n","\n","#with zipfile.ZipFile('drive/My Drive/Colab Notebooks/ner_dataset.csv.zip','r') as zip_ref:\n","#    zip_ref.extractall('drive/My Drive/Colab Notebooks')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"l4SU7e1dsUz3"},"source":["# https://www.kaggle.com/abhinavwalia95/entity-annotated-corpus 에서 nar_dataset.csv.zip을 다운로드\n","data = pd.read_csv(\"drive/My Drive/Colab Notebooks/ner_dataset.csv\", encoding=\"latin1\")\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"arGxlRQRsU2E"},"source":["# sentence : 문장 idx\n","# word : 문장을 구성하는 단어\n","# POS : 형태소\n","# Tag : BIO\n","data[:5]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"q0yPV4r6sb7f"},"source":["print(len(data))\n","# nunique() 유니크의 갯수 추출\n","print(data['Sentence #'].nunique())\n","print(data['Word'].nunique())\n","print(data['Tag'].nunique())\n","\n","print(data.groupby('Tag').size().reset_index(name='count'))\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"h55kwxX_tl8-"},"source":["# 데이터에 True 가 있는지 확인\n","print('데이터에 Null 값이 있는지 유무 : ' + str(data.isnull().values.any()))\n","data.isnull().sum()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bHTbMJ2-xTGJ"},"source":["# Sentence # 의 NaN값을 위에 있는 데이터 값으로 채움\n","data = data.fillna(method = 'ffill')\n","data['Word'] = data['Word'].str.lower()\n","print('sentence # 열의 중복을 제거한 값의 개수 : {}'.format(data['Sentence #'].nunique()))\n","print('Word 열의 중복을 제거한 값의 개수 : {}'.format(data.Word.nunique()))\n","print('Tag 열의 중복을 제거한 값의 개수 : {}'.format(data.Tag.nunique()))  #BIO 구분의 개수"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"aKKHv_9Nsb-N"},"source":["# datagram.values는 array형식이기 때문에 list로 변환\n","# zip을 통해서 하나로 묶은 뒤 단어, BIO 형태를 만듬 ('Stive' , 'B-Per')\n","func = lambda temp: [(w,t) for w, t in zip(temp[\"Word\"].values.tolist(), temp['Tag'].values.tolist())]\n","\n","# apply와 groupby를 통해서 Sentence를 기준으로 분류\n","# 왜 groupby를 통해서 빼지 않았는가  = groupby는 연산이 부가적으로 필요하기 떄문에 \n","# 변수를 합치는 연산을 생성한 뒤 사용한것\n","tagged_sentences = [t for t in data.groupby(\"Sentence #\").apply(func)]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_svite76rOjJ"},"source":["print(\"전체 샘플 개수: {}\".format(len(tagged_sentences)))\n","ner_tags"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"K7Uip2N5shw1"},"source":["sentences, ner_tags = [], [] \n","for tagged_sentence in tagged_sentences: # 47,959개의 문장 샘플을 1개씩 불러온다.\n","    sentence, tag_info = zip(*tagged_sentence) # 각 샘플에서 단어들은 sentence에 개체명 태깅 정보들은 tag_info에 저장.\n"," \n","    sentences.append(list(sentence)) # 각 샘플에서 단어 정보만 저장한다.\n","    ner_tags.append(list(tag_info)) # 각 샘플에서 개체명 태깅 정보만 저장한다."],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"EPFRFHqetLn5"},"source":["# 40정도의 길이\n","print('샘플의 최대 길이 : %d' % max(len(l) for l in sentences))\n","print('샘플의 평균 길이 : %f' % (sum(map(len, sentences))/len(sentences)))\n","plt.hist([len(s) for s in sentences], bins=50)\n","plt.xlabel('length of samples')\n","plt.ylabel('number of samples')\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PJYopvAFEAHR"},"source":["# 지정된 단어를 인덱스 1에 지정\n","src_tokenizer = Tokenizer(oov_token='OOV')\n","src_tokenizer.fit_on_texts(sentences)\n","tar_tokenizer = Tokenizer(lower = False)\n","tar_tokenizer.fit_on_texts(ner_tags)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VYsGy3geqHxu"},"source":["src_tokenizer.word_index['OOV']"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6UJ2_uTbEBfG"},"source":["# 전체 단어 사이즈\n","vocab_size = len(src_tokenizer.word_index) + 1\n","# 전체 테그 사이즈\n","tag_size = len(tar_tokenizer.word_index) + 1 "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dCSrsP6cGg6v"},"source":["# 정수인코딩\n","# 1. Tokenizer로 토큰틀 생성\n","# 2. fit_on_text를 통해서 텍스트에 정수인덱스를 부여(word_index를 통해서 확인가능)\n","# 3. fit_to_sequences()를 통해 기존 단어를 정수로 변환\n","\n","x_train = src_tokenizer.texts_to_sequences(sentences)\n","y_train = tar_tokenizer.texts_to_sequences(ner_tags)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PuT6rvQuWry7"},"source":["x_train"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nP4H1AwGJPtp"},"source":["# 예측결과를 문자화할 index를 저장\n","\n","word_to_index = src_tokenizer.word_index\n","index_to_word = src_tokenizer.index_word\n","ner_to_index = tar_tokenizer.word_index\n","index_to_ner = tar_tokenizer.index_word\n","index_to_ner[0] = 'PAD'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5CTwe9FlJwKz"},"source":["decoded = []\n","for index in x_train[0]:\n","    decoded.append(index_to_word[index])\n","print('기존문장 : {}'.format(sentences[0]))\n","print('디코딩문장 : {}'.format(decoded))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"r8oExjvkKqnB"},"source":["# 대부분의 문장이 60을 넘지 않음 max = 70 지정\n","max_len = 70\n","\n","# 뒤의 부족한 부분은 0으로 채움\n","x_train = pad_sequences(x_train, padding = 'post', maxlen=max_len)\n","y_train = pad_sequences(y_train, padding = 'post', maxlen=max_len)\n","\n","# 학습데이터 분류\n","x_train, x_test, y_train, y_test = train_test_split(x_train, y_train, test_size = 0.2, random_state=777)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tHPlsUQ6oZFq"},"source":["# 정수시퀀스를 array변경\n","y_train = to_categorical(y_train, num_classes=tag_size)\n","y_test = to_categorical(y_test, num_classes=tag_size)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kF4wt3hlYiak"},"source":["y_train"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"OvCiwuluKvj0"},"source":["!pip install seqeval\n","from keras.callbacks import Callback\n","from seqeval.metrics import f1_score, classification_report"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Dm0t1AqQM0Uy"},"source":["# F1-score가 지금까지 중 가장 높은 경우\n","# o값이 많기 때문에 모델의 성능은 좋게 나올 수 있음\n","# 하지만 실제 값을 맞추는 것이 아니기 때문에 이를 판단할 기준이 필요하고 이를 f1_score를 통해\n","# 조화평균을 계산하여 각 요소들의 조화평균값이 가장 높은 모델을 저장함\n","\n","class F1score(Callback):\n","    def __init__(self, value = 0.0, use_char=True):\n","        super(F1score, self).__init__()\n","        self.value = value\n","        self.use_char = use_char\n","\n","    def sequences_to_tags(self, sequences): # 예측값을 index_to_ner를 사용하여 태깅 정보로 변경하는 함수.\n","      result = []\n","      for sequence in sequences: \n","          tag = []\n","          for pred in sequence: # 시퀀스로부터 예측값을 하나씩 꺼낸다.\n","              pred_index = np.argmax(pred) # 예를 들어 [0, 0, 1, 0 ,0]라면 1의 인덱스인 2를 리턴한다.\n","              tag.append(index_to_ner[pred_index].replace(\"PAD\", \"O\")) # 'PAD'는 'O'로 변경\n","          result.append(tag)\n","      return result\n","\n","    # 에포크가 끝날 때마다 실행되는 함수\n","    def on_epoch_end(self, epoch, logs={}):\n","\n","      # char Embedding을 사용하는 경우\n","      if self.use_char:\n","          # validation_data : 각단계마다 모델을 평가할 기준이 되는 x, y값을 저장\n","        X_test = self.validation_data[0]\n","        X_char_test = self.validation_data[1]\n","        y_test = self.validation_data[2]\n","        y_predicted = self.model.predict([X_test, X_char_test])\n","\n","      else:\n","        X_test = self.validation_data[0]\n","        y_test = self.validation_data[1]\n","        y_predicted = self.model.predict([X_test])\n","\n","      pred_tags = self.sequences_to_tags(y_predicted)\n","      test_tags = self.sequences_to_tags(y_test)\n","\n","      score = f1_score(pred_tags, test_tags)\n","      print(' - f1: {:04.2f}'.format(score * 100))\n","      print(classification_report(test_tags, pred_tags))\n","\n","\n","      if score > self.value:\n","        print('f1_score improved from %f to %f, saving model to best_model.h5'%(self.value, score))\n","        # 가장 점수 높은 모델을 저장, 주소변경 필요\n","        self.model.save('drive/My Drive/Colab Notebooks/best_model.h5')\n","        self.value = score\n","      else:\n","        print('f1_score did not improve from %f'%(self.value))\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Fb_9VMHcn0E9"},"source":["\n","!pip install git+https://www.github.com/keras-team/keras-contrib.git"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ekngUbqbPFJv"},"source":["from keras.models import Sequential\n","from keras.layers import LSTM, Embedding, Dense, TimeDistributed, Dropout, Bidirectional\n","from keras_contrib.layers import CRF\n","from keras_contrib.losses import crf_loss\n","from keras_contrib.metrics import crf_viterbi_accuracy\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"IQwKWSfGPFPG"},"source":["model = Sequential()\n","model.add(Embedding(input_dim=vocab_size, output_dim=20, input_length=max_len, mask_zero=True))\n","model.add(Bidirectional(LSTM(units=50, return_sequences=True, recurrent_dropout=0.1)))\n","model.add(TimeDistributed(Dense(50, activation=\"relu\")))\n","crf = CRF(tag_size)\n","model.add(crf)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qgAt1r3xPFRg"},"source":["model.compile(optimizer=\"adam\", loss=crf.loss_function, metrics=[crf.accuracy])\n","history = model.fit(x_train, y_train, batch_size = 128, epochs = 25, validation_split = 0.1, verbose = 1, callbacks=[F1score(use_char=False)])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"SXfqvHuuPFT9"},"source":["from keras.models import load_model\n","bilstm_crf_model = load_model('drive/My Drive/Colab Notebooks/best_model.h5', custom_objects={'CRF':CRF,\n","                                                  'crf_loss':crf_loss,\n","                                                  'crf_viterbi_accuracy':crf_viterbi_accuracy})"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Qk2QExSyPFY3"},"source":["f1score = F1score(use_char=False)\n","\n","y_predicted = bilstm_crf_model.predict([x_test])\n","pred_tags = f1score.sequences_to_tags(y_predicted)\n","test_tags = f1score.sequences_to_tags(y_test)\n","print(classification_report(test_tags, pred_tags))\n","print(\"F1-score: {:.1%}\".format(f1_score(test_tags, pred_tags)))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8u6Noj3tPFei"},"source":["new_encoded=[]\n","new_sentence='Mr. Heo said South Korea has become a worldwide leader'.lower().split()\n","for w in new_sentence:\n","    try:\n","      new_encoded.append(word_to_index.get(w,1))\n","    except KeyError:\n","      new_encoded.append(word_to_index['OOV'])\n","      # 모델이 모르는 단어에 대해서는 'OOV'의 인덱스인 1로 인코딩\n","\n","new_padded = pad_sequences([new_encoded], padding=\"post\", value=0, maxlen=max_len)\n","\n","p = bilstm_crf_model.predict(np.array([new_padded[0]]))\n","p = np.argmax(p, axis=-1)\n","print(\"{:15}||{}\".format(\"단어\", \"예측값\"))\n","print(30 * \"=\")\n","for w, pred in zip(new_sentence, p[0]):\n","    print(\"{:15}: {:5}\".format(w, index_to_ner[pred]))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Hl8Ft1eGIfWD"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"k4nmV2L1LXIu"},"source":[""],"execution_count":null,"outputs":[]}]}